{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic of Langgraph in Local system** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*install the dependencies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Kunal.Mishra\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Kunal.Mishra\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Kunal.Mishra\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: langchain==0.3.10 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 1)) (0.3.10)\n",
      "Requirement already satisfied: langchain-mistralai==0.2.3 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 2)) (0.2.3)\n",
      "Requirement already satisfied: langgraph==0.2.60 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 3)) (0.2.60)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from -r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (3.10.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (0.3.49)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (0.1.147)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.3.10->-r requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse<1,>=0.3.1 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15.1 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (0.21.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langgraph==0.2.60->-r requirements.txt (line 3)) (2.0.23)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langgraph==0.2.60->-r requirements.txt (line 3)) (0.1.59)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10->-r requirements.txt (line 1)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10->-r requirements.txt (line 1)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10->-r requirements.txt (line 1)) (1.15.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph==0.2.60->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.60->-r requirements.txt (line 3)) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10->-r requirements.txt (line 1)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain==0.3.10->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain==0.3.10->-r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.10->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers<1,>=0.15.1->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (0.29.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (2024.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain==0.3.10->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.3.10->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from anyio->httpx<1,>=0.25.2->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kunal.mishra\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai==0.2.3->-r requirements.txt (line 2)) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=\"tVKig5OytBqAtxcjOh9n0gz0RlJ5hEn9\"\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"]=\"tVKig5OytBqAtxcjOh9n0gz0RlJ5hEn9\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatMistralAI(\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompts\n",
    "sys_prompt=\"You are a helpful assistant that translates English to Japanese and also in french\"\n",
    "hum_prompt=\"Translate the user sentence without giving more details, just the translation: I love programming.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke([\n",
    "    SystemMessage(content=sys_prompt),\n",
    "    HumanMessage(content=hum_prompt)\n",
    "]).content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese: プログラミングが大好きです。\n",
      "\n",
      "French: J'adore la programmation.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict,TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path,'r') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,ToolMessage,AIMessage,HumanMessage\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_path=\"cv.txt\"\n",
    "job_path=\"job_descrip.txt\"\n",
    "start_state={\"messages\":{\"cv_path\":cv_path,\"job_path\":job_path}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CV\n",
    "def get_cv_content(state: dict): # The state here is -> {\"messages\": {\"cv_path\": cv_path, \"job_path\": job_path}}\n",
    "    print(\"***** get_cv_content *****\")\n",
    "  \n",
    "    # Extract the CV file path from the state\n",
    "    cv_path = state['messages']['cv_path']\n",
    "    cv_content = read_file(cv_path)\n",
    "    \n",
    "    # Create a ToolMessage object with the CV content and a unique tool call ID\n",
    "    tool_call = ToolMessage(\n",
    "        content=cv_content,\n",
    "        tool_call_id=str(uuid.uuid4())\n",
    "    )\n",
    "\n",
    "    # Update the state with the CV content and retain the job file path\n",
    "    new_state = {\n",
    "        \"messages\": {\n",
    "            \"job_path\": state['messages']['job_path'],\n",
    "            \"cv_content\": tool_call\n",
    "        }\n",
    "    }\n",
    "    return new_state\n",
    "\n",
    "# Read Job Offer\n",
    "def get_job_description(state: dict): # The state here will be the get_cv_content result -> {\"messages\": {\"job_path\": job_path, \"cv_content\": ___}}\n",
    "    print(\"***** get_job_description *****\")\n",
    "\n",
    "    # Extract the job description file path from the state\n",
    "    job_path = state['messages']['job_path']\n",
    "    \n",
    "    # Read the content of the job description file\n",
    "    job_content = read_file(job_path)\n",
    "\n",
    "    # Create a ToolMessage object with the job description content and a unique tool call ID\n",
    "    tool_call = ToolMessage(\n",
    "        content=job_content,\n",
    "        tool_call_id=str(uuid.uuid4())\n",
    "    )\n",
    "\n",
    "    # Update the state with the job description content and retain the CV content\n",
    "    new_state = {\n",
    "        \"messages\": {\n",
    "            \"cv_content\": state['messages']['cv_content'],\n",
    "            \"job_content\": tool_call\n",
    "        }\n",
    "    }\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Match\n",
    "def evaluate_match(state: dict): # The state here will be the get_job_description result -> {\"messages\": {\"cv_content\": ___, \"job_content\": ___}}\n",
    "    print(\"***** evaluate_match *****\")\n",
    "\n",
    "    # Extract the CV and job description content from the state\n",
    "    cv_content = state[\"messages\"][\"cv_content\"].content\n",
    "    job_content = state[\"messages\"][\"job_content\"].content\n",
    "\n",
    "    # Create the evaluation prompts\n",
    "    hum_evaluation_template = \"\"\"CV:\n",
    "    {cv}\n",
    "    ===\n",
    "    Job Description:\n",
    "    {job}\n",
    "    ===\n",
    "    Evaluate whether the CV aligns with the job description provided. Clearly indicate the degree of match and provide specific reasons for your assessment, ensuring a detailed and professional response:\n",
    "    \"\"\"\n",
    "    hum_evaluation_prompt = hum_evaluation_template.format(cv=cv_content, job=job_content)\n",
    "    sys_evaluation_prompt = \"\"\"You are tasked with evaluating whether the CV aligns with the job description provided. Clearly indicate the degree of match and provide specific, detailed reasons for your assessment.\"\"\"\n",
    "\n",
    "    # Invoke the LLM with the evaluation prompts\n",
    "    response = llm.invoke([SystemMessage(content=sys_evaluation_prompt),\n",
    "                           HumanMessage(content=hum_evaluation_prompt)])\n",
    "    content = response.content.strip()\n",
    "\n",
    "    # Create an AIMessage object with the evaluation response and a unique AI call ID\n",
    "    ai_call = AIMessage(\n",
    "        content=content,\n",
    "        ai_call_id=str(uuid.uuid4())\n",
    "    )\n",
    "\n",
    "    # Update the state with the evaluation response\n",
    "    new_state = {\n",
    "        \"messages\": {\n",
    "            \"evaluation\": ai_call\n",
    "        }\n",
    "    }\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Email\n",
    "def generate_email(state: dict): # The state here will be the evaluate_match result -> {\"messages\": {\"evaluation\": ___}}\n",
    "    print(\"***** generate_email *****\")\n",
    "\n",
    "    # Extract the evaluation result from the state\n",
    "    evaluation_result = state[\"messages\"][\"evaluation\"].content\n",
    "\n",
    "    # Create the email prompts\n",
    "    hum_email_template = \"\"\"Job Application Evaluation:\n",
    "    {evaluation}\n",
    "    ===\n",
    "    Based on the evaluation of the match between the candidate's CV and the job description, draft an email to the candidate communicating the result of the assessment. Clearly indicate whether or not the candidate has been selected for the position and provide the reasons for the decision. Ensure the tone is polite, professional, and respectful, starting the email with a courteous acknowledgment.\n",
    "    Email:\n",
    "    \"\"\"\n",
    "    hum_email_prompt = hum_email_template.format(evaluation=evaluation_result)\n",
    "    sys_email_prompt = \"\"\"You are a hiring manager tasked with drafting an email to a candidate regarding the result of their job application assessment. Clearly communicate whether the candidate has been selected for the position, and provide reasons for the decision. Maintain a polite, professional, and respectful tone, starting the email with a courteous acknowledgment.\"\"\"\n",
    "\n",
    "    # Invoke the LLM with the email prompts\n",
    "    response = llm.invoke([SystemMessage(content=sys_email_prompt),\n",
    "                           HumanMessage(content=hum_email_prompt)])\n",
    "    content = response.content.strip()\n",
    "\n",
    "    # Create an AIMessage object with the email content and a unique AI call ID\n",
    "    ai_call = AIMessage(\n",
    "        content=content,\n",
    "        ai_call_id=str(uuid.uuid4())\n",
    "    )\n",
    "\n",
    "    # Update the state with the email content\n",
    "    new_state = {\n",
    "        \"messages\": {\n",
    "            \"email\": ai_call\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Graph with the initial state\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# We add the nodes that corresponds to the functions we defined. We have to give them a name\n",
    "workflow.add_node(\"read_cv\", get_cv_content)\n",
    "workflow.add_node(\"get_job_description\", get_job_description)\n",
    "workflow.add_node(\"evaluate_match\", evaluate_match)\n",
    "workflow.add_node(\"generate_email\", generate_email)\n",
    "\n",
    "# We add the edges that connect the nodes.\n",
    "## We start from the START and indicate the next node, that in this case is \"read_cv\"\n",
    "workflow.add_edge(START, \"read_cv\")\n",
    "workflow.add_edge(\"read_cv\", \"get_job_description\")\n",
    "workflow.add_edge(\"get_job_description\", \"evaluate_match\")\n",
    "workflow.add_edge(\"evaluate_match\", \"generate_email\")\n",
    "workflow.add_edge(\"generate_email\", END)\n",
    "\n",
    "# We compile the graph\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** get_cv_content *****\n",
      "Current Output: {'read_cv': {'messages': {'job_path': 'job_descrip.txt', 'cv_content': ToolMessage(content='Kunal Kumar Mishra\\nSonia Vihar, Delhi, 110094\\nEmail: Kunalmishravats@gmail.com | Phone: +91-8743052389\\nGitHub LinkedIn\\nEducation\\nâ€¢ Bhagwan Parshuram Institute of Technology, Delhi\\nB. Tech in Computer Science and Engineering, Percentage: 84% September 2021 - June 2024 â€¢ Ambedkar Institute of Technology, Board of Technical Education, Delhi\\nDiploma in ITES&M, Percentage: 75% August 2018 â€“ July 2021\\nExperience\\nAI/ML Engineer, MTSL, Noida July 2024 - Presentâ€¢ Streamlined And Automated The Signature Extraction Process By Utilizing AWS Sagemaker, AWS\\nLambda, And AWS ECR In The Design And Implementation Of The SMC Signature Extraction\\nSolution. â€¢ I created and refined the Almonds Data Engineering project using AWS Glue, Athena, and\\nRedshift in order to create robust data pipelines, increase the efficiency of data processing, and\\nenable perceptive analytics.\\nProjects â€¢ Solar Irradiance Forecasting Project\\nDeveloped a deep learning model using Python, Sklearn, and TensorFlow to forecast solar irradiance.\\nEngineered features for accurate predictions and documented project progress for collaboration. â€¢ Dogecoin Price Prediction Project\\nBuilt a machine learning model using Python and Sklearn to forecast Dogecoinâ€™s prices. Utilized data\\npreprocessing techniques, implemented regression algorithms, and documented outcomes.\\nAchievements â€¢ The Robust Self-Attention Multi-Horizon Model (RSAM) was introduced in a study on\\nimprovements in solar irradiance prediction that was published in the International Journal of\\nResearch Publication and Reviews, Vol. 5, No. 3, March 2024. â€¢ Microsoft MTA Certification â€¢ took part in the 2022 Google Hash Code â€¢ took part in the 2022 Google Cloud Kickstart. â€¢ July 2023: Microsoft ML Cloud Challenge Program\\nSkills\\nProgramming Languages: Python, C/C++, JavaScript, SQL (MySQL)\\nMachine Learning & AI: TensorFlow, PyTorch, Keras, HuggingFace, LLMs, scikit-learn\\nWeb Development: ReactJS, JavaScript, HTML/CSS, Flask, Streamlit\\nCloud Computing: AWS Lambda, SageMaker, S3, Bedrock, ECR, Athena, Glue, Redshift, Amazon\\nQ, IAM, Google Cloud Platform (GCP), BigQuery, Google Cloud Storage, Cloud Spanner, AlloyDB\\nData Engineering: Data warehousing, ETL/ELT processes, MongoDB, PySpark\\nInfrastructure: Docker, CI/CD, Terraform\\nTools & Technologies: Pandas, Matplotlib, NumPy, Seaborn, Linux ', tool_call_id='18600b5d-1797-4ede-878b-c59367aefc0d')}}}\n",
      "***** get_job_description *****\n",
      "Current Output: {'get_job_description': {'messages': {'cv_content': ToolMessage(content='Kunal Kumar Mishra\\nSonia Vihar, Delhi, 110094\\nEmail: Kunalmishravats@gmail.com | Phone: +91-8743052389\\nGitHub LinkedIn\\nEducation\\nâ€¢ Bhagwan Parshuram Institute of Technology, Delhi\\nB. Tech in Computer Science and Engineering, Percentage: 84% September 2021 - June 2024 â€¢ Ambedkar Institute of Technology, Board of Technical Education, Delhi\\nDiploma in ITES&M, Percentage: 75% August 2018 â€“ July 2021\\nExperience\\nAI/ML Engineer, MTSL, Noida July 2024 - Presentâ€¢ Streamlined And Automated The Signature Extraction Process By Utilizing AWS Sagemaker, AWS\\nLambda, And AWS ECR In The Design And Implementation Of The SMC Signature Extraction\\nSolution. â€¢ I created and refined the Almonds Data Engineering project using AWS Glue, Athena, and\\nRedshift in order to create robust data pipelines, increase the efficiency of data processing, and\\nenable perceptive analytics.\\nProjects â€¢ Solar Irradiance Forecasting Project\\nDeveloped a deep learning model using Python, Sklearn, and TensorFlow to forecast solar irradiance.\\nEngineered features for accurate predictions and documented project progress for collaboration. â€¢ Dogecoin Price Prediction Project\\nBuilt a machine learning model using Python and Sklearn to forecast Dogecoinâ€™s prices. Utilized data\\npreprocessing techniques, implemented regression algorithms, and documented outcomes.\\nAchievements â€¢ The Robust Self-Attention Multi-Horizon Model (RSAM) was introduced in a study on\\nimprovements in solar irradiance prediction that was published in the International Journal of\\nResearch Publication and Reviews, Vol. 5, No. 3, March 2024. â€¢ Microsoft MTA Certification â€¢ took part in the 2022 Google Hash Code â€¢ took part in the 2022 Google Cloud Kickstart. â€¢ July 2023: Microsoft ML Cloud Challenge Program\\nSkills\\nProgramming Languages: Python, C/C++, JavaScript, SQL (MySQL)\\nMachine Learning & AI: TensorFlow, PyTorch, Keras, HuggingFace, LLMs, scikit-learn\\nWeb Development: ReactJS, JavaScript, HTML/CSS, Flask, Streamlit\\nCloud Computing: AWS Lambda, SageMaker, S3, Bedrock, ECR, Athena, Glue, Redshift, Amazon\\nQ, IAM, Google Cloud Platform (GCP), BigQuery, Google Cloud Storage, Cloud Spanner, AlloyDB\\nData Engineering: Data warehousing, ETL/ELT processes, MongoDB, PySpark\\nInfrastructure: Docker, CI/CD, Terraform\\nTools & Technologies: Pandas, Matplotlib, NumPy, Seaborn, Linux ', tool_call_id='18600b5d-1797-4ede-878b-c59367aefc0d'), 'job_content': ToolMessage(content=\"MAIgents' Web Intelligence team develops cutting-edge AI-powered services that improve user experiences across MAIgents Search and MAIgents Navigator. Our mission is to deliver innovative solutions that save time, provide valuable insights, and drive user satisfaction in a secure online environment.\\n\\n**MAIgents Shop** is a dynamic platform that brings together products from various sellers, offering users a streamlined shopping experience. Through advanced AI technologies, MAIgents Shop delivers accurate search results, personalized recommendations, and valuable product insights like reviews and price trends.\\n\\nWe are looking for a **Data & Applied Scientist II** to join our team and contribute to the development of algorithms, models, and insights that enhance our search and shopping capabilities. If youâ€™re passionate about data and innovation, this is your opportunity to make a global impact.\\n\\n**Responsibilities**\\n- Design and optimize algorithms to improve search results and recommendations.\\n- Analyze large datasets to identify trends and build predictive models.\\n- Collaborate with engineers and product managers to enhance platform performance.\\n- Conduct experiments and A/B tests to evaluate and refine algorithms.\\n- Present insights and recommendations to stakeholders.\\n\\n**Qualifications**\\n- Bachelorâ€™s degree in a related field and experience in data science or machine learning.\\n- Proficiency in Python; familiarity with SQL and other tools is a plus.\\n- Strong problem-solving skills and ability to work in a team-oriented environment.\\n- Knowledge of A/B testing and recommendation systems is preferred.\\n\\nJoin MAIgents and shape the future of online shopping!\", tool_call_id='e9a9f4f5-880e-4dda-8dd4-5a9bb5b58886')}}}\n",
      "***** evaluate_match *****\n",
      "Current Output: {'evaluate_match': {'messages': {'evaluation': AIMessage(content=\"### Degree of Match: High\\n\\nKunal Kumar Mishra's CV aligns well with the job description for the **Data & Applied Scientist II** position at MAIgents. Here are the specific, detailed reasons for this assessment:\\n\\n#### Education\\n- **Degree**: Kunal holds a B. Tech in Computer Science and Engineering, which is highly relevant to the field of data science and machine learning. This aligns well with the job description's requirement for a bachelor's degree in a related field.\\n- **Percentage**: His academic performance (84% in B. Tech and 75% in Diploma) indicates a strong foundation in his field of study.\\n\\n#### Experience\\n- **AI/ML Engineer Role**: Kunal's experience as an AI/ML Engineer at MTSL involves tasks that are directly relevant to the job description. He has worked on streamlining and automating processes using AWS services, which demonstrates his ability to handle large datasets and build predictive models.\\n- **Projects**: His projects, such as the Solar Irradiance Forecasting Project and Dogecoin Price Prediction Project, showcase his ability to develop machine learning models and conduct data analysis, which are key responsibilities for the Data & Applied Scientist II role.\\n\\n#### Skills\\n- **Programming Languages**: Proficiency in Python is a key requirement for the job, and Kunal lists Python as one of his primary programming languages. His familiarity with SQL is also a plus.\\n- **Machine Learning & AI**: Kunal's experience with TensorFlow, PyTorch, Keras, and scikit-learn aligns well with the need for expertise in machine learning and AI.\\n- **Data Engineering**: His skills in data warehousing, ETL/ELT processes, and tools like AWS Glue, Athena, and Redshift are highly relevant for analyzing large datasets and building predictive models.\\n- **Cloud Computing**: His experience with AWS and Google Cloud Platform (GCP) is beneficial for the role, as it indicates his ability to work with cloud-based data and services.\\n- **Tools & Technologies**: His proficiency with tools like Pandas, Matplotlib, NumPy, and Seaborn is valuable for data analysis and visualization.\\n\\n#### Achievements\\n- **Publications and Certifications**: Kunal's publication in the International Journal of Research Publication and Reviews and his Microsoft MTA Certification demonstrate his expertise and commitment to the field.\\n- **Competitions**: Participation in Google Hash Code and Google Cloud Kickstart shows his engagement with the latest technologies and his problem-solving skills.\\n\\n#### Soft Skills\\n- **Problem-Solving**: His experience in creating and refining data engineering projects and developing machine learning models indicates strong problem-solving skills.\\n- **Team Collaboration**: His involvement in collaborative projects and his ability to document project progress suggest that he can work effectively in a team-oriented environment.\\n\\n### Areas for Improvement\\n- **A/B Testing**: While Kunal's experience is strong in many areas, there is no explicit mention of A/B testing in his CV. This is a preferred skill for the job, so he might need to highlight any relevant experience or be prepared to discuss how he could apply his skills to A/B testing.\\n- **Recommendation Systems**: Although his projects involve predictive modeling, there is no direct mention of recommendation systems. He should be ready to discuss how his experience can be applied to building recommendation algorithms.\\n\\n### Conclusion\\nOverall, Kunal Kumar Mishra's CV shows a high degree of alignment with the job description for the Data & Applied Scientist II position at MAIgents. His educational background, relevant experience, and technical skills make him a strong candidate for the role. With a bit more emphasis on A/B testing and recommendation systems, his application would be even more compelling.\", additional_kwargs={}, response_metadata={}, ai_call_id='4257aaa3-c08c-402d-b358-a1a5e47e959d')}}}\n",
      "***** generate_email *****\n",
      "Current Output: {'generate_email': {'messages': {'email': AIMessage(content='Subject: Application Update for Data & Applied Scientist II Position\\n\\nDear Kunal,\\n\\nThank you for your interest in the Data & Applied Scientist II position at MAIgents and for taking the time to apply. We appreciate the opportunity to review your application and learn about your background and experiences.\\n\\nI am pleased to inform you that, based on our assessment, your application has been successful. We were impressed with the strong alignment between your qualifications and the requirements of the role. Here are some of the key factors that contributed to our decision:\\n\\n1. **Educational Background**: Your B. Tech in Computer Science and Engineering, along with your strong academic performance, provides a solid foundation for the role.\\n\\n2. **Relevant Experience**: Your experience as an AI/ML Engineer at MTSL, where you worked on streamlining and automating processes using AWS services, is directly relevant to the responsibilities of the Data & Applied Scientist II position.\\n\\n3. **Technical Skills**: Your proficiency in Python, SQL, TensorFlow, PyTorch, Keras, scikit-learn, and various data engineering tools demonstrates your capability to handle the technical demands of the role.\\n\\n4. **Projects and Achievements**: Your projects, such as the Solar Irradiance Forecasting Project and Dogecoin Price Prediction Project, showcase your ability to develop machine learning models and conduct data analysis. Your publications and certifications further highlight your expertise and commitment to the field.\\n\\n5. **Soft Skills**: Your problem-solving skills and ability to work effectively in a team-oriented environment are valuable assets for our collaborative work culture.\\n\\nWhile your application is strong, we would like to discuss further how your experience can be applied to A/B testing and recommendation systems, which are important aspects of the role. We believe that your background and skills make you a great fit for our team, and we are excited about the possibility of having you join us.\\n\\nPlease let us know if you have any questions or if there is any additional information you would like to share. We look forward to the possibility of welcoming you to MAIgents.\\n\\nBest regards,\\n\\n[Your Name]\\n[Your Position]\\nMAIgents', additional_kwargs={}, response_metadata={}, ai_call_id='204d5e48-4792-4bea-b53b-2c6f847cc3be')}}}\n",
      "\n",
      "***** Process completed successfully!! *****\n",
      "\n",
      "Subject: Application Update for Data & Applied Scientist II Position\n",
      "\n",
      "Dear Kunal,\n",
      "\n",
      "Thank you for your interest in the Data & Applied Scientist II position at MAIgents and for taking the time to apply. We appreciate the opportunity to review your application and learn about your background and experiences.\n",
      "\n",
      "I am pleased to inform you that, based on our assessment, your application has been successful. We were impressed with the strong alignment between your qualifications and the requirements of the role. Here are some of the key factors that contributed to our decision:\n",
      "\n",
      "1. **Educational Background**: Your B. Tech in Computer Science and Engineering, along with your strong academic performance, provides a solid foundation for the role.\n",
      "\n",
      "2. **Relevant Experience**: Your experience as an AI/ML Engineer at MTSL, where you worked on streamlining and automating processes using AWS services, is directly relevant to the responsibilities of the Data & Applied Scientist II position.\n",
      "\n",
      "3. **Technical Skills**: Your proficiency in Python, SQL, TensorFlow, PyTorch, Keras, scikit-learn, and various data engineering tools demonstrates your capability to handle the technical demands of the role.\n",
      "\n",
      "4. **Projects and Achievements**: Your projects, such as the Solar Irradiance Forecasting Project and Dogecoin Price Prediction Project, showcase your ability to develop machine learning models and conduct data analysis. Your publications and certifications further highlight your expertise and commitment to the field.\n",
      "\n",
      "5. **Soft Skills**: Your problem-solving skills and ability to work effectively in a team-oriented environment are valuable assets for our collaborative work culture.\n",
      "\n",
      "While your application is strong, we would like to discuss further how your experience can be applied to A/B testing and recommendation systems, which are important aspects of the role. We believe that your background and skills make you a great fit for our team, and we are excited about the possibility of having you join us.\n",
      "\n",
      "Please let us know if you have any questions or if there is any additional information you would like to share. We look forward to the possibility of welcoming you to MAIgents.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Position]\n",
      "MAIgents\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the graph\n",
    "for output in graph.stream(start_state):\n",
    "    print(\"Current Output:\", output)\n",
    "\n",
    "print(\"\\n***** Process completed successfully!! *****\\n\")\n",
    "print(output['generate_email']['messages']['email'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
